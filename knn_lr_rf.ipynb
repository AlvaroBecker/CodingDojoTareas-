{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlvaroBecker/CodingDojoTareas-/blob/main/knn_lr_rf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6M9M7tRL7f7"
      },
      "source": [
        "La tarea es:\n",
        "\n",
        "1) Utilizar un modelo de regresión logística e intentar tanto la regularización L1 como L2. Esta es una gran oportunidad para mostrar que afinar los hiperparámetros puede afectar los resultados del modelo. \n",
        "\n",
        "2) Después de hacer eso, intenter usar los modelos de KNN y bosque aleatorio. \n",
        "\n",
        "3) Aborden estas preguntas en una celda de texto al final de sus códigos:\n",
        "\n",
        "¿Cuál es el modelo que mejor funciona? \n",
        "¿Cuáles hiperparámetros afinaron para cada uno de los modelos? ¿Hay algún modelo que les gustó más y por qué?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WdxZyc_0L7f9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.neighbors._classification\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZqWCJamUZm0",
        "outputId": "7cc54790-5873-48c1-d33a-658ed54e83da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url='/content/drive/MyDrive/Coding_dojo/semana 8/Regresión logística, bosque aleatorio o KNN/Wine_cultivars.csv'\n",
        "df=pd.read_csv(url)"
      ],
      "metadata": {
        "id": "3Qofp9NMr1qD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "9tBzgtCBL7f_",
        "outputId": "e0e45216-ff76-469b-8865-82c71a4cf954"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Class label  Alcohol  Malic Acid   Ash  Alcalinity of ash  Magnesium  \\\n",
              "0              1    14.23        1.71  2.43               15.6        127   \n",
              "1              1    13.20        1.78  2.14               11.2        100   \n",
              "2              1    13.16        2.36  2.67               18.6        101   \n",
              "3              1    14.37        1.95  2.50               16.8        113   \n",
              "4              1    13.24        2.59  2.87               21.0        118   \n",
              "..           ...      ...         ...   ...                ...        ...   \n",
              "173            3    13.71        5.65  2.45               20.5         95   \n",
              "174            3    13.40        3.91  2.48               23.0        102   \n",
              "175            3    13.27        4.28  2.26               20.0        120   \n",
              "176            3    13.17        2.59  2.37               20.0        120   \n",
              "177            3    14.13        4.10  2.74               24.5         96   \n",
              "\n",
              "     Total phenols  Flavanoids  Nonflavonid phenols  Proanthocyanins  \\\n",
              "0             2.80        3.06                 0.28             2.29   \n",
              "1             2.65        2.76                 0.26             1.28   \n",
              "2             2.80        3.24                 0.30             2.81   \n",
              "3             3.85        3.49                 0.24             2.18   \n",
              "4             2.80        2.69                 0.39             1.82   \n",
              "..             ...         ...                  ...              ...   \n",
              "173           1.68        0.61                 0.52             1.06   \n",
              "174           1.80        0.75                 0.43             1.41   \n",
              "175           1.59        0.69                 0.43             1.35   \n",
              "176           1.65        0.68                 0.53             1.46   \n",
              "177           2.05        0.76                 0.56             1.35   \n",
              "\n",
              "     Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
              "0               5.64  1.04                          3.92     1065  \n",
              "1               4.38  1.05                          3.40     1050  \n",
              "2               5.68  1.03                          3.17     1185  \n",
              "3               7.80  0.86                          3.45     1480  \n",
              "4               4.32  1.04                          2.93      735  \n",
              "..               ...   ...                           ...      ...  \n",
              "173             7.70  0.64                          1.74      740  \n",
              "174             7.30  0.70                          1.56      750  \n",
              "175            10.20  0.59                          1.56      835  \n",
              "176             9.30  0.60                          1.62      840  \n",
              "177             9.20  0.61                          1.60      560  \n",
              "\n",
              "[178 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d907e37-96e3-4ccf-8675-a31dcac0f8b1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class label</th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Malic Acid</th>\n",
              "      <th>Ash</th>\n",
              "      <th>Alcalinity of ash</th>\n",
              "      <th>Magnesium</th>\n",
              "      <th>Total phenols</th>\n",
              "      <th>Flavanoids</th>\n",
              "      <th>Nonflavonid phenols</th>\n",
              "      <th>Proanthocyanins</th>\n",
              "      <th>Color intensity</th>\n",
              "      <th>Hue</th>\n",
              "      <th>OD280/OD315 of diluted wines</th>\n",
              "      <th>Proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>3</td>\n",
              "      <td>13.71</td>\n",
              "      <td>5.65</td>\n",
              "      <td>2.45</td>\n",
              "      <td>20.5</td>\n",
              "      <td>95</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.06</td>\n",
              "      <td>7.70</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.74</td>\n",
              "      <td>740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>3</td>\n",
              "      <td>13.40</td>\n",
              "      <td>3.91</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.0</td>\n",
              "      <td>102</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.41</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>3</td>\n",
              "      <td>13.27</td>\n",
              "      <td>4.28</td>\n",
              "      <td>2.26</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.35</td>\n",
              "      <td>10.20</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.56</td>\n",
              "      <td>835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>3</td>\n",
              "      <td>13.17</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.37</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.46</td>\n",
              "      <td>9.30</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.62</td>\n",
              "      <td>840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>3</td>\n",
              "      <td>14.13</td>\n",
              "      <td>4.10</td>\n",
              "      <td>2.74</td>\n",
              "      <td>24.5</td>\n",
              "      <td>96</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.20</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.60</td>\n",
              "      <td>560</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d907e37-96e3-4ccf-8675-a31dcac0f8b1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d907e37-96e3-4ccf-8675-a31dcac0f8b1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d907e37-96e3-4ccf-8675-a31dcac0f8b1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXFeMKXnL7gA",
        "outputId": "f6722cc5-c195-48da-e8af-ce89f60aed46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 178 entries, 0 to 177\n",
            "Data columns (total 14 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   Class label                   178 non-null    int64  \n",
            " 1   Alcohol                       178 non-null    float64\n",
            " 2   Malic Acid                    178 non-null    float64\n",
            " 3   Ash                           178 non-null    float64\n",
            " 4   Alcalinity of ash             178 non-null    float64\n",
            " 5   Magnesium                     178 non-null    int64  \n",
            " 6   Total phenols                 178 non-null    float64\n",
            " 7   Flavanoids                    178 non-null    float64\n",
            " 8   Nonflavonid phenols           178 non-null    float64\n",
            " 9   Proanthocyanins               178 non-null    float64\n",
            " 10  Color intensity               178 non-null    float64\n",
            " 11  Hue                           178 non-null    float64\n",
            " 12  OD280/OD315 of diluted wines  178 non-null    float64\n",
            " 13  Proline                       178 non-null    int64  \n",
            "dtypes: float64(11), int64(3)\n",
            "memory usage: 19.6 KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2-S-UHVL7gA",
        "outputId": "53d35a54-04a1-455d-d005-af085ee2b03b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Logistic Regression - l1 regularization): 0.9259259259259259\n",
            "Accuracy (Logistic Regression - l2 regularization): 0.9629629629629629\n",
            "Accuracy (KNN - 5 neighbors): 0.9444444444444444\n",
            "Accuracy (Random Forest - 100 estimators): 0.9629629629629629\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Función para crear un modelo de Regresión Logística\n",
        "def evaluate_logreg(penalty_type):\n",
        "    steps = [('scaler', StandardScaler()),\n",
        "             ('logreg', LogisticRegression(penalty=penalty_type, solver='liblinear' if penalty_type == 'l1' else 'lbfgs'))]\n",
        "    pipeline = Pipeline(steps)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)\n",
        "    logreg_scaled = pipeline.fit(X_train, y_train)\n",
        "    print('Accuracy (Logistic Regression - {} regularization): {}'.format(penalty_type, pipeline.score(X_test, y_test)))\n",
        "\n",
        "# Función para crear un modelo de KNN\n",
        "def evaluate_knn(n_neighbors):\n",
        "    steps = [('scaler', StandardScaler()),\n",
        "             ('knn', KNeighborsClassifier(n_neighbors=n_neighbors))]\n",
        "    pipeline = Pipeline(steps)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)\n",
        "    knn_scaled = pipeline.fit(X_train, y_train)\n",
        "    print('Accuracy (KNN - {} neighbors): {}'.format(n_neighbors, pipeline.score(X_test, y_test)))\n",
        "\n",
        "#  Función para crear un modelo de Random Forest\n",
        "def evaluate_rf(n_estimators):\n",
        "    rf = RandomForestClassifier(n_estimators=n_estimators, random_state=21)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)\n",
        "    rf.fit(X_train, y_train)\n",
        "    print('Accuracy (Random Forest - {} estimators): {}'.format(n_estimators, rf.score(X_test, y_test)))\n",
        "\n",
        "X = df.drop('Class label', axis=1).values\n",
        "y = df['Class label'].values\n",
        "\n",
        "# Evaluamos el modelo de Regresión Logística con regularización L1\n",
        "evaluate_logreg('l1')\n",
        "\n",
        "# Evaluamos el modelo de Regresión Logística con regularización L2\n",
        "evaluate_logreg('l2')\n",
        "\n",
        "# Evaluamos el modelo de KNN con 5 vecinos\n",
        "evaluate_knn(5)\n",
        "\n",
        "# Evaluamos el modelo de Random Forest con 100 estimadores\n",
        "evaluate_rf(100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1izrkxHdL7gB"
      },
      "source": [
        "¿Cuál es el modelo que mejor funciona? \n",
        "¿Cuáles hiperparámetros afinaron para cada uno de los modelos? ¿Hay algún modelo que les gustó más y por qué?\n",
        "\n",
        "El modelo que mejor funciona es un empate entre la Regresión Logística con regularización L2 y el Random Forest con 100 estimadores, ambos con una precisión de 0.9629.\n",
        "\n",
        "Los hiperparámetros afinados para cada uno de los modelos son:\n",
        "\n",
        "Regresión Logística: tipo de regularización (L1 o L2).\n",
        "KNN: número de vecinos (se usó 5 en este caso).\n",
        "Random Forest: número de estimadores (se usó 100 en este caso)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}